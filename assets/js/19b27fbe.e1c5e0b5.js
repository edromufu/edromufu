"use strict";(self.webpackChunkedrom=self.webpackChunkedrom||[]).push([[1813],{5680:(e,n,o)=>{o.d(n,{xA:()=>l,yg:()=>g});var a=o(6540);function r(e,n,o){return n in e?Object.defineProperty(e,n,{value:o,enumerable:!0,configurable:!0,writable:!0}):e[n]=o,e}function t(e,n){var o=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);n&&(a=a.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),o.push.apply(o,a)}return o}function i(e){for(var n=1;n<arguments.length;n++){var o=null!=arguments[n]?arguments[n]:{};n%2?t(Object(o),!0).forEach((function(n){r(e,n,o[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(o)):t(Object(o)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(o,n))}))}return e}function s(e,n){if(null==e)return{};var o,a,r=function(e,n){if(null==e)return{};var o,a,r={},t=Object.keys(e);for(a=0;a<t.length;a++)o=t[a],n.indexOf(o)>=0||(r[o]=e[o]);return r}(e,n);if(Object.getOwnPropertySymbols){var t=Object.getOwnPropertySymbols(e);for(a=0;a<t.length;a++)o=t[a],n.indexOf(o)>=0||Object.prototype.propertyIsEnumerable.call(e,o)&&(r[o]=e[o])}return r}var c=a.createContext({}),d=function(e){var n=a.useContext(c),o=n;return e&&(o="function"==typeof e?e(n):i(i({},n),e)),o},l=function(e){var n=d(e.components);return a.createElement(c.Provider,{value:n},e.children)},u="mdxType",m={inlineCode:"code",wrapper:function(e){var n=e.children;return a.createElement(a.Fragment,{},n)}},p=a.forwardRef((function(e,n){var o=e.components,r=e.mdxType,t=e.originalType,c=e.parentName,l=s(e,["components","mdxType","originalType","parentName"]),u=d(o),p=r,g=u["".concat(c,".").concat(p)]||u[p]||m[p]||t;return o?a.createElement(g,i(i({ref:n},l),{},{components:o})):a.createElement(g,i({ref:n},l))}));function g(e,n){var o=arguments,r=n&&n.mdxType;if("string"==typeof e||r){var t=o.length,i=new Array(t);i[0]=p;var s={};for(var c in n)hasOwnProperty.call(n,c)&&(s[c]=n[c]);s.originalType=e,s[u]="string"==typeof e?e:r,i[1]=s;for(var d=2;d<t;d++)i[d]=o[d];return a.createElement.apply(null,i)}return a.createElement.apply(null,o)}p.displayName="MDXCreateElement"},7069:(e,n,o)=>{o.r(n),o.d(n,{assets:()=>c,contentTitle:()=>i,default:()=>m,frontMatter:()=>t,metadata:()=>s,toc:()=>d});var a=o(8168),r=(o(6540),o(5680));const t={id:"running_inference.py",title:"running_inference.py",desrcion:"Nesta se\xe7\xe3o teremos um explica\xe7\xe3o sobre o c\xf3digo running_inference.py",slug:"/running_inference",sidebar_position:3},i=void 0,s={unversionedId:"vision/codes/running_inference.py",id:"vision/codes/running_inference.py",title:"running_inference.py",description:"Nesta se\xe7\xe3o teremos um explica\xe7\xe3o detalhada sobre o c\xf3digo running_inference.py",source:"@site/docs/vision/codes/running_inference.md",sourceDirName:"vision/codes",slug:"/running_inference",permalink:"/edromufu/docs/running_inference",draft:!1,editUrl:"https://github.com/edromufu/edromufu/tree/master/edrom-docs/docs/vision/codes/running_inference.md",tags:[],version:"current",sidebarPosition:3,frontMatter:{id:"running_inference.py",title:"running_inference.py",desrcion:"Nesta se\xe7\xe3o teremos um explica\xe7\xe3o sobre o c\xf3digo running_inference.py",slug:"/running_inference",sidebar_position:3},sidebar:"tutorialSidebar",previous:{title:"connecting_and_showing.py",permalink:"/edromufu/docs/connecting_and_showing"},next:{title:"Treinamento da rede neural",permalink:"/edromufu/docs/category/treinamento-da-rede-neural"}},c={},d=[{value:"get_cnn_files()",id:"get_cnn_files",level:2},{value:"read_cnn_architecture()",id:"read_cnn_architecture",level:2},{value:"Set_model_input()",id:"set_model_input",level:2},{value:"Detect_model()",id:"detect_model",level:2},{value:"Draw_results()",id:"draw_results",level:2}],l={toc:d},u="wrapper";function m(e){let{components:n,...o}=e;return(0,r.yg)(u,(0,a.A)({},l,o,{components:n,mdxType:"MDXLayout"}),(0,r.yg)("p",null,"Nesta se\xe7\xe3o teremos um explica\xe7\xe3o detalhada sobre o c\xf3digo running_inference.py"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-py",metastring:'title="object_finder/src/running_inference.py"',title:'"object_finder/src/running_inference.py"'},"#!/usr/bin/env python3\n# coding=utf-8\n\nimport os\nimport cv2\nimport numpy as np\nimport time\n\n\noutline_color_list = [(255, 0, 0), (0, 0, 255), (0, 0, 255)]\n")),(0,r.yg)("p",null,"Nesse c\xf3digo temos algumas importa\xe7\xf5es:"),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("p",{parentName:"li"},"\u201cos\u201d = Biblioteca que possui algumas fun\xe7\xf5es que imitam as do sistema operacional")),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("p",{parentName:"li"},"\u201ccv2\u201d = OpenCV, Biblioteca para trabalhar com imagens")),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("p",{parentName:"li"},"\u201cNumpy\u201d = Biblioteca para o processamento de grandes n\xfameros, vetores e matrizes.")),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("p",{parentName:"li"},"\u201ctime\u201d = Biblioteca que trabalha que possui v\xe1rias fun\xe7\xf5es referentes ao tempo."))),(0,r.yg)("h2",{id:"get_cnn_files"},"get_cnn_files()"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-py",metastring:'title="object_finder/src/running_inference.py"',title:'"object_finder/src/running_inference.py"'},'def get_cnn_files():\n\n    robocup_folder = os.path.join(os.path.expanduser(\'~\'), "edromufu/src/vision/robocup_cnn_files")\n\n    config_file = os.path.join(robocup_folder, "yolov4-tiny-obj.cfg")\n    weights_file = os.path.join(robocup_folder, "yolov4-tiny-obj_best.weights")\n\n    return read_cnn_architecture(config_file, weights_file)\n')),(0,r.yg)("p",null,'LUCAS ESTEVE AQ. Esta fun\xe7\xe3o recupera os nomes dos arquivos de uma rede neural convolucional (CNN) especificando as rotas dos arquivos de configura\xe7\xe3o e pesos. A fun\xe7\xe3o usa a biblioteca os para juntar o caminho do diret\xf3rio home do usu\xe1rio com a pasta "vis\xe3o/robocup_cnn_files" espec\xedfica onde os arquivos est\xe3o localizados. Os arquivos espec\xedficos dentro desta pasta s\xe3o "yolov4-tiny-obj.cfg" e "yolov4-tiny-obj_best.weights". A fun\xe7\xe3o ent\xe3o retorna a sa\xedda da fun\xe7\xe3o ',(0,r.yg)("em",{parentName:"p"},"read_cnn_architecture()"),", passando os arquivos config_file e weights_file como argumentos."),(0,r.yg)("h2",{id:"read_cnn_architecture"},"read_cnn_architecture()"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-py",metastring:'title="object_finder/src/running_inference.py"',title:'"object_finder/src/running_inference.py"'},'def read_cnn_architecture(config_file, weights_file):\n\n    net = cv2.dnn.readNet(config_file, weights_file, "darknet")\n\n    return net\n')),(0,r.yg)("p",null,"Esta fun\xe7\xe3o l\xea a arquitetura e os pesos de uma rede neural convolucional (CNN) usando a biblioteca OpenCV. Ele recebe dois argumentos, o caminho do arquivo de configura\xe7\xe3o e o caminho do arquivo de pesos. A fun\xe7\xe3o, ent\xe3o, usa a fun\xe7\xe3o ",(0,r.yg)("em",{parentName:"p"},"cv2.dnn.readNet()"),' da biblioteca OpenCV para carregar a rede com o config_file e o weights_file dados e passando a string "darknet" como terceiro argumento. Esta fun\xe7\xe3o retorna o modelo CNN carregado representado pela vari\xe1vel "net".'),(0,r.yg)("h2",{id:"set_model_input"},"Set_model_input()"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-py",metastring:'title="object_finder/src/running_inference.py"',title:'"object_finder/src/running_inference.py"'},"def set_model_input(net):\n\n    model = cv2.dnn.DetectionModel(net)\n    model.setInputParams(size=(416,416), scale=1/255, swapRB=True)\n    \n    return model\n")),(0,r.yg)("p",null,"Esta fun\xe7\xe3o define a entrada do modelo de uma rede neural convolucional (CNN) usando a biblioteca OpenCV. Ela recebe um argumento, que \xe9 o modelo da rede neural carregado anteriormente (net). A fun\xe7\xe3o cria uma vari\xe1vel model, que \xe9 uma inst\xe2ncia da classe ",(0,r.yg)("em",{parentName:"p"},"cv2.dnn.DetectionModel")," e passa a rede neural carregada (net) como argumento. Em seguida, \xe9 utilizado o m\xe9todo setInputParams da classe model para definir os par\xe2metros de entrada da rede neural, que s\xe3o o tamanho da imagem de entrada (416x416 pixels), a escala dos valores de pixel (1/255) e a troca do canal de cor vermelho e azul (swapRB=True). Por fim, a fun\xe7\xe3o retorna o modelo configurado."),(0,r.yg)("h2",{id:"detect_model"},"Detect_model()"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-py",metastring:'title="object_finder/src/running_inference.py"',title:'"object_finder/src/running_inference.py"'},'def detect_model(model, current_frame):\n    \n    start_time = time.time()\n    classes, scores, boxes = model.detect(current_frame, 0.85, 0.4)\n    finish_time = time.time()\n    fps = 1/(finish_time-start_time)\n    \n    #print(f"Classes: {classes}, Scores: {scores}")\n    #print(f"Boxes: {boxes}")\n    #print("FPS: ", fps)\n    #print(\'\\n\')\n\n    return classes, scores, boxes, int(fps)\n')),(0,r.yg)("p",null,"Esta fun\xe7\xe3o detecta objetos em uma imagem usando um modelo de rede neural convolucional (CNN) previamente configurado. Ela recebe dois argumentos, o modelo configurado (model) e a imagem atual (current_frame). A fun\xe7\xe3o inicia uma contagem de tempo, chamando a fun\xe7\xe3o ",(0,r.yg)("em",{parentName:"p"},"time.time()"),", para medir o desempenho do modelo. Ent\xe3o, a fun\xe7\xe3o usa o m\xe9todo ",(0,r.yg)("em",{parentName:"p"},"detect()")," do modelo para detectar objetos na imagem atual e obt\xe9m tr\xeas vari\xe1veis de sa\xedda: classes (as classes dos objetos detectados), scores (a confian\xe7a das detec\xe7\xf5es) e boxes (as caixas delimitadoras dos objetos detectados). Os par\xe2metros 0.85 e 0.4 passados para ",(0,r.yg)("em",{parentName:"p"},"detect()")," s\xe3o respectivamente o limiar de confian\xe7a m\xednima e o limiar de maxima supress\xe3o. Em seguida, a fun\xe7\xe3o calcula a taxa de quadros por segundo (FPS) como 1 dividido pela diferen\xe7a entre o tempo final e o tempo inicial. A fun\xe7\xe3o retorna as classes, scores, boxes e FPS."),(0,r.yg)("h2",{id:"draw_results"},"Draw_results()"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-py",metastring:'title="object_finder/src/running_inference.py"',title:'"object_finder/src/running_inference.py"'},'def draw_results(frame, classes, scores, boxes):\n\n    # Draw the bounding boxes\n\n    for i in range(len(boxes)):\n        [x_top, y_top, roi_width, roi_height] = boxes[i]\n        #p1 = (x_top, y_top)\n        #p2 = (x_top + roi_width, y_top + roi_height)\n        p3 = (x_top, y_top - 5)\n\n        x_center = round(x_top+(roi_width/2))\n        y_center = round(y_top+(roi_height/2))\n        radius = round((roi_width+roi_height)/4)\n        \n        #cv2.rectangle(frame, p1, p2, outline_color_list[classes[i]], 2)\n        cv2.circle (frame,(x_center,y_center),radius, outline_color_list[classes[i]],2 )\n        confidence = str(round(float(scores[i]), 2))\n        \n        label = "Ball"\n\n        cv2.putText(frame, label+" " + confidence, p3, cv2.FONT_HERSHEY_PLAIN, 1, (255,255,255), 1)\n')),(0,r.yg)("p",null,'Esta fun\xe7\xe3o desenha as detec\xe7\xf5es de objetos em uma imagem. Ela recebe quatro argumentos: a imagem (frame), as classes dos objetos detectados (classes), as confian\xe7as das detec\xe7\xf5es (scores) e as caixas delimitadoras dos objetos detectados (boxes). A fun\xe7\xe3o usa um loop para percorrer todas as caixas delimitadoras e, para cada uma, extrai as coordenadas x e y do canto superior esquerdo, bem como a largura e a altura da caixa. Em seguida, calcula o centro da caixa e o raio. Em vez de desenhar uma caixa em volta do objeto detectado, o c\xf3digo desenha um c\xedrculo no centro do objeto com o raio calculado. Em seguida, o c\xf3digo adiciona o texto "Bola" junto com a confian\xe7a da detec\xe7\xe3o na imagem, logo acima do objeto detectado. A fun\xe7\xe3o n\xe3o retorna nenhum valor, pois modifica a imagem passada como argumento.'))}m.isMDXComponent=!0}}]);
"use strict";(self.webpackChunkedrom=self.webpackChunkedrom||[]).push([[1813],{5680:(e,n,o)=>{o.d(n,{xA:()=>d,yg:()=>f});var r=o(6540);function t(e,n,o){return n in e?Object.defineProperty(e,n,{value:o,enumerable:!0,configurable:!0,writable:!0}):e[n]=o,e}function i(e,n){var o=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);n&&(r=r.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),o.push.apply(o,r)}return o}function a(e){for(var n=1;n<arguments.length;n++){var o=null!=arguments[n]?arguments[n]:{};n%2?i(Object(o),!0).forEach((function(n){t(e,n,o[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(o)):i(Object(o)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(o,n))}))}return e}function s(e,n){if(null==e)return{};var o,r,t=function(e,n){if(null==e)return{};var o,r,t={},i=Object.keys(e);for(r=0;r<i.length;r++)o=i[r],n.indexOf(o)>=0||(t[o]=e[o]);return t}(e,n);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(r=0;r<i.length;r++)o=i[r],n.indexOf(o)>=0||Object.prototype.propertyIsEnumerable.call(e,o)&&(t[o]=e[o])}return t}var c=r.createContext({}),l=function(e){var n=r.useContext(c),o=n;return e&&(o="function"==typeof e?e(n):a(a({},n),e)),o},d=function(e){var n=l(e.components);return r.createElement(c.Provider,{value:n},e.children)},u="mdxType",m={inlineCode:"code",wrapper:function(e){var n=e.children;return r.createElement(r.Fragment,{},n)}},p=r.forwardRef((function(e,n){var o=e.components,t=e.mdxType,i=e.originalType,c=e.parentName,d=s(e,["components","mdxType","originalType","parentName"]),u=l(o),p=t,f=u["".concat(c,".").concat(p)]||u[p]||m[p]||i;return o?r.createElement(f,a(a({ref:n},d),{},{components:o})):r.createElement(f,a({ref:n},d))}));function f(e,n){var o=arguments,t=n&&n.mdxType;if("string"==typeof e||t){var i=o.length,a=new Array(i);a[0]=p;var s={};for(var c in n)hasOwnProperty.call(n,c)&&(s[c]=n[c]);s.originalType=e,s[u]="string"==typeof e?e:t,a[1]=s;for(var l=2;l<i;l++)a[l]=o[l];return r.createElement.apply(null,a)}return r.createElement.apply(null,o)}p.displayName="MDXCreateElement"},7069:(e,n,o)=>{o.r(n),o.d(n,{assets:()=>c,contentTitle:()=>a,default:()=>m,frontMatter:()=>i,metadata:()=>s,toc:()=>l});var r=o(8168),t=(o(6540),o(5680));const i={id:"running_inference.py",title:"running_inference.py",description:"Nesta se\xe7\xe3o teremos um explica\xe7\xe3o sobre o c\xf3digo running_inference.py",slug:"/running_inference",sidebar_position:3},a=void 0,s={unversionedId:"vision/codes/running_inference.py",id:"vision/codes/running_inference.py",title:"running_inference.py",description:"Nesta se\xe7\xe3o teremos um explica\xe7\xe3o sobre o c\xf3digo running_inference.py",source:"@site/docs/vision/codes/running_inference.md",sourceDirName:"vision/codes",slug:"/running_inference",permalink:"/edromufu/docs/running_inference",draft:!1,editUrl:"https://github.com/edromufu/edromufu/tree/master/edrom-docs/docs/vision/codes/running_inference.md",tags:[],version:"current",sidebarPosition:3,frontMatter:{id:"running_inference.py",title:"running_inference.py",description:"Nesta se\xe7\xe3o teremos um explica\xe7\xe3o sobre o c\xf3digo running_inference.py",slug:"/running_inference",sidebar_position:3},sidebar:"tutorialSidebar",previous:{title:"connecting_and_showing.py",permalink:"/edromufu/docs/connecting_and_showing"},next:{title:"Treinamento da rede neural",permalink:"/edromufu/docs/category/treinamento-da-rede-neural"}},c={},l=[{value:"Set_model_input()",id:"set_model_input",level:2},{value:"Detect_model()",id:"detect_model",level:2}],d={toc:l},u="wrapper";function m(e){let{components:n,...o}=e;return(0,t.yg)(u,(0,r.A)({},d,o,{components:n,mdxType:"MDXLayout"}),(0,t.yg)("p",null,"Nesta se\xe7\xe3o teremos um explica\xe7\xe3o detalhada sobre o c\xf3digo running_inference.py"),(0,t.yg)("pre",null,(0,t.yg)("code",{parentName:"pre",className:"language-py",metastring:'title="object_finder/src/running_inference.py"',title:'"object_finder/src/running_inference.py"'},"#!/usr/bin/env python3\n# coding=utf-8\n\nfrom ultralytics import YOLO\nimport os\nimport cv2\nimport numpy as np\nimport time\n\noutline_color_list = [(255, 0, 0), (0, 0, 255), (0, 0, 255)]\n")),(0,t.yg)("p",null,"Nesse c\xf3digo temos algumas importa\xe7\xf5es:"),(0,t.yg)("ul",null,(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("p",{parentName:"li"},"\u201cos\u201d = Biblioteca que possui algumas fun\xe7\xf5es que imitam as do sistema operacional")),(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("p",{parentName:"li"},"\u201ccv2\u201d = OpenCV, Biblioteca para trabalhar com imagens")),(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("p",{parentName:"li"},"\u201cNumpy\u201d = Biblioteca para o processamento de grandes n\xfameros, vetores e matrizes.")),(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("p",{parentName:"li"},"\u201ctime\u201d = Biblioteca que trabalha que possui v\xe1rias fun\xe7\xf5es referentes ao tempo.")),(0,t.yg)("li",{parentName:"ul"},(0,t.yg)("p",{parentName:"li"},'"ultralytics" = Fun\xe7\xe3o da biblioteca YOLO utilizada para implementa\xe7\xe3o e execu\xe7\xe3o de algoritmos de detec\xe7\xe3o de objetos.'))),(0,t.yg)("h2",{id:"set_model_input"},"Set_model_input()"),(0,t.yg)("pre",null,(0,t.yg)("code",{parentName:"pre",className:"language-py",metastring:'title="object_finder/src/running_inference.py"',title:'"object_finder/src/running_inference.py"'},"\ndef set_model_input():\n        \n    '''Gets the CNN filenames, despite the PC file structure.'''\n    \n    robocup_folder = os.path.join(os.path.expanduser('~'), \"edromufu/src/vision/robocup_cnn_files\")\n    net = os.path.join(robocup_folder, \"yolov8n-vision.pt\")\n    \n    model = YOLO(net)\n    \n    return model\n")),(0,t.yg)("p",null,'Esta fun\xe7\xe3o define a entrada do modelo de uma rede neural convolucional (CNN) utilizando a biblioteca OpenCV. Ela recebe nenhum argumento e retorna uma inst\xe2ncia do modelo YOLO carregado com os arquivos de configura\xe7\xe3o e pesos especificados. Inicialmente, o caminho para os arquivos \xe9 constru\xeddo concatenando o diret\xf3rio home do usu\xe1rio com a pasta espec\xedfica onde os arquivos est\xe3o localizados. Os arquivos espec\xedficos dentro desta pasta s\xe3o "yolov8n-vision.pt". Em seguida, a fun\xe7\xe3o carrega o modelo YOLO com o arquivo especificado utilizando a classe YOLO. O modelo carregado \xe9 ent\xe3o retornado.'),(0,t.yg)("h2",{id:"detect_model"},"Detect_model()"),(0,t.yg)("pre",null,(0,t.yg)("code",{parentName:"pre",className:"language-py",metastring:'title="object_finder/src/running_inference.py"',title:'"object_finder/src/running_inference.py"'},'\ndef detect_model(model, current_frame):\n    \n    start_time = time.time()\n    results = model.predict(source=current_frame,\n                            conf=0.25,  \n                            imgsz=(640,448), \n                            max_det=10, \n                            device=0, \n                            verbose=False) \n    \n    classes = results[0].boxes.cls.tolist()\n    scores = results[0].boxes.conf.tolist() \n    boxes = results[0].boxes.xywh.tolist()  \n\n    finish_time = time.time()\n    fps_inf = 1/(finish_time-start_time)\n    \n    print(f"Classes: {classes}, Scores: {scores}")\n    print(f"Boxes: {boxes}")\n    print(f\'FPS da infer\xeancia: {fps_inf}\')\n\n\n    inference_frame=results[0].plot()\n\n    return classes, scores, boxes, inference_frame\n')),(0,t.yg)("p",null,"Esta fun\xe7\xe3o detecta objetos em uma imagem utilizando um modelo de rede neural convolucional (CNN) previamente configurado. Ela recebe dois argumentos: o modelo configurado (model) e o quadro atual (current_frame). A fun\xe7\xe3o inicia uma contagem de tempo para medir o desempenho do modelo utilizando a fun\xe7\xe3o time.time(). Em seguida, a fun\xe7\xe3o chama o m\xe9todo predict() do modelo para realizar a detec\xe7\xe3o de objetos na imagem atual. Os par\xe2metros fornecidos para predict() incluem o quadro de origem (source), o limiar de confian\xe7a m\xednima (conf), o tamanho da imagem (imgsz), o n\xfamero m\xe1ximo de detec\xe7\xf5es por imagem (max_det), o dispositivo de execu\xe7\xe3o (device) e a op\xe7\xe3o de verbose (verbose). A fun\xe7\xe3o ent\xe3o extrai as classes (\xedndices de cada objeto identificado), scores (n\xedvel de confian\xe7a respectivo a cada objeto identificado) e caixas delimitadoras (coordenadas x e y do centro, altura e comprimeto para cada objeto) das detec\xe7\xf5es realizadas. Posteriormente, calcula a taxa de quadros por segundo (FPS) como o inverso da diferen\xe7a entre o tempo final e o tempo inicial. Por fim, a fun\xe7\xe3o retorna as classes, scores, caixas delimitadoras e uma representa\xe7\xe3o visual do resultado da infer\xeancia."))}m.isMDXComponent=!0}}]);